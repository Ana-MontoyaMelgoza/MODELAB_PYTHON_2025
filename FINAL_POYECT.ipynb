{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771cd60d",
   "metadata": {},
   "source": [
    "# FINAL POYECT\n",
    "\n",
    "## MODELAB PYTHON 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00ea5207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMultivariate Environmental Analysis\\n\\nAuthor: Ana Montoya\\nPython: 3.13.5\\nLibraries: numpy, pandas, matplotlib, scikit-learn, scipy\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multivariate Environmental Analysis\n",
    "\n",
    "Author: Ana Montoya\n",
    "Python: 3.13.5\n",
    "Libraries: numpy, pandas, matplotlib, scikit-learn, scipy\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cefece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports & Configuration\n",
    "# =========================\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1891343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import braycurtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0563ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Paths and global settings\n",
    "# -------------------------\n",
    "DATA_PATH = \"./BD/bd_exercises_curse.csv\"\n",
    "OUT_DIR   = \"outputs_mds\"\n",
    "FIG_DIR   = os.path.join(OUT_DIR, \"01_figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd356c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Load the dataset\n",
    "# =========================\n",
    "def load_dataset(path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "bd_data = load_dataset(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc0d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Variable selection\n",
    "# =========================\n",
    "def select_variables(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Choose numeric variables for analysis and group variables for interpretation.\n",
    "\n",
    "    The function returns:\n",
    "      numeric_cols: list of numeric columns present in the dataset\n",
    "      group_cols:   list of grouping columns (if present)\n",
    "    \"\"\"\n",
    "    # Candidate numeric features\n",
    "    num_candidates = [\n",
    "        \"chlorophy_microg_l\", \"sal_psu\", \"temp_c\", \"depth_m\",\n",
    "        \"do_mg_l\", \"do_percent_sat\", \"turbidity_fnu\",\n",
    "        \"sp_cond_microsiemens_cm\", \"cond_microsiemens_cm\",\n",
    "        \"dic_micromol_kg\", \"ta_micromol_kg\"\n",
    "    ]\n",
    "    numeric_cols = [c for c in num_candidates if c in df.columns]\n",
    "\n",
    "    # Optional metadata for plotting/interpretation\n",
    "    group_candidates = [\"estuary\", \"area\", \"season\", \"layer_depth\", \"station\"]\n",
    "    group_cols = [c for c in group_candidates if c in df.columns]\n",
    "\n",
    "    # Save chosen columns\n",
    "    pd.Series(numeric_cols).to_csv(os.path.join(OUT_DIR, \"02_numeric_columns_used.csv\"), index=False, header=[\"numeric_cols\"])\n",
    "    pd.Series(group_cols).to_csv(os.path.join(OUT_DIR, \"02_group_columns_used.csv\"), index=False, header=[\"group_cols\"])\n",
    "    return numeric_cols, group_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6845392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Imputation + Standardization\n",
    "# =========================\n",
    "def impute_and_standardize(df: pd.DataFrame, numeric_cols):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      X_imputed (np.array), X_scaled (np.array), z_df (DataFrame z-scores)\n",
    "    \"\"\"\n",
    "    X_raw = df[numeric_cols].copy()\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    X_imputed = imputer.fit_transform(X_raw)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    z_df = pd.DataFrame(X_scaled, columns=[f\"z_{c}\" for c in numeric_cols], index=df.index)\n",
    "    z_df.to_csv(os.path.join(OUT_DIR, \"03_zscores.csv\"), index=False)\n",
    "    return X_imputed, X_scaled, z_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc025dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Dissimilarity Matrices\n",
    "# =========================\n",
    "def compute_dissimilarities(X_scaled: np.ndarray, X_nonneg: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute Euclidean (on standardized features) and Bray-Curtis (on non-negative features).\n",
    "    Returns:\n",
    "      D_euclid (n x n), D_bray (n x n)\n",
    "    \"\"\"\n",
    "    # Euclidean on standardized vars\n",
    "    D_euclid = pairwise_distances(X_scaled, metric=\"euclidean\")\n",
    "\n",
    "    # Bray-Curtis expects non-negative values\n",
    "    n = X_nonneg.shape[0]\n",
    "    D_bray = np.zeros((n, n), dtype=float)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = braycurtis(X_nonneg[i], X_nonneg[j])\n",
    "            D_bray[i, j] = d\n",
    "            D_bray[j, i] = d\n",
    "\n",
    "    # Save to CSV (square matrices)\n",
    "    pd.DataFrame(D_euclid).to_csv(os.path.join(OUT_DIR, \"04_D_euclidean.csv\"), index=False)\n",
    "    pd.DataFrame(D_bray).to_csv(os.path.join(OUT_DIR, \"04_D_braycurtis.csv\"), index=False)\n",
    "    return D_euclid, D_bray\n",
    "# =========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de9f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  MDS (metric & non-metric)\n",
    "# =========================\n",
    "def run_mds(D: np.ndarray, metric: bool, random_state: int = RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Run 2D MDS given a precomputed dissimilarity matrix.\n",
    "    metric=True for metric MDS, False for non-metric MDS.\n",
    "    Returns:\n",
    "      Y (n x 2) configuration, stress (float)\n",
    "    \"\"\"\n",
    "    mds = MDS(\n",
    "        n_components=2,\n",
    "        metric=metric,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        random_state=random_state,\n",
    "        n_init=4,\n",
    "        max_iter=500\n",
    "        # Avoid using normalized_stress for broad compatibility across scikit-learn versions\n",
    "    )\n",
    "    Y = mds.fit_transform(D)\n",
    "    stress = float(mds.stress_)\n",
    "    return Y, stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bafd9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Plots â€“ single-purpose figures\n",
    "# =========================\n",
    "def scatter_mds(Y: np.ndarray, title: str, df: pd.DataFrame, group_cols):\n",
    "    \"\"\"\n",
    "    Create a scatter of MDS coordinates.\n",
    "    - Uses marker shape variation for one grouping column if available\n",
    "    - No custom colors are set (follows the course constraint)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    # Choose one grouping column for markers if available\n",
    "    marker_by = group_cols[0] if len(group_cols) > 0 else None\n",
    "\n",
    "    if marker_by and marker_by in df.columns:\n",
    "        codes = pd.Categorical(df[marker_by]).codes\n",
    "        marker_list = [\"o\", \"s\", \"^\", \"D\", \"P\", \"X\", \"*\", \"v\", \"<\", \">\"]\n",
    "        for mk in np.unique(codes):\n",
    "            idx = np.where(codes == mk)[0]\n",
    "            plt.scatter(Y[idx, 0], Y[idx, 1], marker=marker_list[mk % len(marker_list)])\n",
    "    else:\n",
    "        plt.scatter(Y[:, 0], Y[:, 1])\n",
    "\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def save_current_fig(filename: str):\n",
    "    out_path = os.path.join(FIG_DIR, filename)\n",
    "    plt.savefig(out_path, dpi=180)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def simple_lonlat_map(df: pd.DataFrame, lon_col=\"longitude\", lat_col=\"latitude\", title=\"Sampling Locations (Lon/Lat)\"):\n",
    "    \"\"\"\n",
    "    Simple lon/lat scatter without basemap (keeps dependencies minimal).\n",
    "    \"\"\"\n",
    "    if lon_col in df.columns and lat_col in df.columns:\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.scatter(df[lon_col], df[lat_col])\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        return save_current_fig(\"00_map_lonlat.png\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c26af689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Markdown Report (equations & references)\n",
    "# =========================\n",
    "def write_markdown_report(numeric_cols, group_cols, stress_dict):\n",
    "    \"\"\"\n",
    "    Write a simple Markdown report including equations and APA references.\n",
    "    \"\"\"\n",
    "    numeric_cols_list = \", \".join(numeric_cols) if numeric_cols else \"N/A\"\n",
    "    group_cols_list   = \", \".join(group_cols) if group_cols else \"N/A\"\n",
    "\n",
    "    report = f\"\"\"\n",
    "# Multidimensional Scaling (MDS) of Environmental Data â€“ Step-by-Step\n",
    "\n",
    "**Dataset:** {os.path.basename(DATA_PATH)}  \n",
    "**Variables used (standardized):** {numeric_cols_list}  \n",
    "**Group metadata (for interpretation):** {group_cols_list}\n",
    "\n",
    "## 1. Preprocessing (Standardization)\n",
    "We standardized each variable using z-scores:  \n",
    "$$ z_{{i}} = \\\\frac{{x_{{i}} - \\\\mu}}{{\\\\sigma}} $$\n",
    "where $x_i$ is the raw value, $\\\\mu$ is the feature mean, and $\\\\sigma$ is the feature standard deviation.\n",
    "\n",
    "## 2. Dissimilarity Matrices\n",
    "- **Euclidean** on standardized variables:  \n",
    "$$ d_{{ij}}^{{(Euc)}} = \\\\sqrt{{\\\\sum_k (z_{{ik}} - z_{{jk}})^2 }} $$\n",
    "- **Brayâ€“Curtis** on non-negative variables:  \n",
    "$$ d_{{ij}}^{{(BC)}} = \\\\frac{{\\\\sum_k |x_{{ik}} - x_{{jk}}|}}{{\\\\sum_k (x_{{ik}} + x_{{jk}})}} $$\n",
    "\n",
    "## 3. Multidimensional Scaling (MDS)\n",
    "We computed **metric** and **non-metric** MDS in 2D. The objective is to find a low-dimensional configuration $\\\\mathbf{{Y}}$ that preserves the original dissimilarities as distances.  \n",
    "A commonly reported loss is Kruskal's stress:  \n",
    "$$ \\\\mathrm{{Stress}} = \\\\sqrt{{ \\\\frac{{\\\\sum_{{i<j}} (d_{{ij}} - \\\\hat{{d}}_{{ij}})^2 }}{{\\\\sum_{{i<j}} d_{{ij}}^2 }} }} $$\n",
    "where $d_{{ij}}$ are observed dissimilarities and $\\\\hat{{d}}_{{ij}}$ are distances in the MDS map.\n",
    "\n",
    "### Results (Stress)\n",
    "- Metric MDS (Euclidean): **{stress_dict.get('metric_euclid', 'n/a'):.6f}**\n",
    "- Non-Metric MDS (Euclidean): **{stress_dict.get('nonmetric_euclid', 'n/a'):.6f}**\n",
    "- Metric MDS (Brayâ€“Curtis): **{stress_dict.get('metric_bray', 'n/a'):.6f}**\n",
    "\n",
    "Lower stress indicates better preservation of the original dissimilarities in 2D.\n",
    "\n",
    "## 4. Interpretation Guide\n",
    "- **Nearby points** in the MDS plots indicate **similar environmental conditions**.\n",
    "- **Far apart points** indicate **contrasting conditions** (e.g., plume vs. coastal sites).\n",
    "- Add metadata (e.g., *estuary*, *area*, *layer_depth*) to better interpret potential ecological gradients.\n",
    "\n",
    "## 5. References (APA-style)\n",
    "- Borg, I., Groenen, P. J. F., & Mair, P. (2013). *Applied Multidimensional Scaling*. Springer.\n",
    "- Gower, J. C. (1966). Some distance properties of latent root and vector methods used in multivariate analysis. *Biometrika, 53*(3-4), 325â€“338.\n",
    "- Kruskal, J. B. (1964). Nonmetric multidimensional scaling: A numerical method. *Psychometrika, 29*(2), 115â€“129.\n",
    "- Legendre, P., & Legendre, L. (2012). *Numerical Ecology* (3rd ed.). Elsevier.\n",
    "- Mardia, K. V., Kent, J. T., & Bibby, J. M. (1979). *Multivariate Analysis*. Academic Press.\n",
    "\n",
    "---\n",
    "\"\"\"\n",
    "    with open(os.path.join(OUT_DIR, \"99_REPORT.md\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "746fda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "#  Main: run the pipeline\n",
    "# =========================\n",
    "def main():\n",
    "    #  Make directories\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    df = load_dataset(DATA_PATH)\n",
    "\n",
    "    # Variable selection\n",
    "    map_path = simple_lonlat_map(df, lon_col=\"longitude\", lat_col=\"latitude\")\n",
    "    numeric_cols, group_cols = select_variables(df)\n",
    "\n",
    "    # Impute + Standardize (z-scores)\n",
    "    X_imputed, X_scaled, z_df = impute_and_standardize(df, numeric_cols)\n",
    "\n",
    "    # For Bray-Curtis, ensure non-negative inputs\n",
    "    X_nonneg = np.clip(X_imputed, a_min=0, a_max=None)\n",
    "\n",
    "    # Dissimilarity matrices\n",
    "    D_euclid, D_bray = compute_dissimilarities(X_scaled, X_nonneg)\n",
    "\n",
    "    # MDS\n",
    "    # Metric MDS (Euclidean)\n",
    "    Y_metric_euclid, stress_metric_euclid = run_mds(D_euclid, metric=True)\n",
    "\n",
    "    # Non-Metric MDS (Euclidean)\n",
    "    Y_nonmetric_euclid, stress_nonmetric_euclid = run_mds(D_euclid, metric=False)\n",
    "\n",
    "    # Metric MDS (Brayâ€“Curtis)\n",
    "    Y_metric_bray, stress_metric_bray = run_mds(D_bray, metric=True)\n",
    "\n",
    "    # Save coordinates with metadata to CSV\n",
    "    out_coords = pd.DataFrame({\n",
    "        \"mds_metric_euclid_dim1\": Y_metric_euclid[:, 0],\n",
    "        \"mds_metric_euclid_dim2\": Y_metric_euclid[:, 1],\n",
    "        \"mds_nonmetric_euclid_dim1\": Y_nonmetric_euclid[:, 0],\n",
    "        \"mds_nonmetric_euclid_dim2\": Y_nonmetric_euclid[:, 1],\n",
    "        \"mds_metric_bray_dim1\": Y_metric_bray[:, 0],\n",
    "        \"mds_metric_bray_dim2\": Y_metric_bray[:, 1],\n",
    "    })\n",
    "    # Append group columns if available\n",
    "    for c in group_cols:\n",
    "        out_coords[c] = df[c].values\n",
    "\n",
    "    out_coords.to_csv(os.path.join(OUT_DIR, \"05_mds_coordinates.csv\"), index=False)\n",
    "\n",
    "    # Plots (one chart per file)\n",
    "    # Metric MDS (Euclidean)\n",
    "    scatter_mds(Y_metric_euclid, f\"Metric MDS (Euclidean)\\nStress={stress_metric_euclid:.4f}\", df, group_cols)\n",
    "    save_current_fig(\"06_metric_mds_euclidean.png\")\n",
    "\n",
    "    # Non-Metric MDS (Euclidean)\n",
    "    scatter_mds(Y_nonmetric_euclid, f\"Non-Metric MDS (Euclidean)\\nStress={stress_nonmetric_euclid:.4f}\", df, group_cols)\n",
    "    save_current_fig(\"07_nonmetric_mds_euclidean.png\")\n",
    "\n",
    "    # Metric MDS (Bray-Curtis)\n",
    "    scatter_mds(Y_metric_bray, f\"Metric MDS (Bray-Curtis)\\nStress={stress_metric_bray:.4f}\", df, group_cols)\n",
    "    save_current_fig(\"08_metric_mds_braycurtis.png\")\n",
    "\n",
    "    # Write Markdown report with equations and references\n",
    "    stress_dict = {\n",
    "        \"metric_euclid\": stress_metric_euclid,\n",
    "        \"nonmetric_euclid\": stress_nonmetric_euclid,\n",
    "        \"metric_bray\": stress_metric_bray\n",
    "    }\n",
    "    write_markdown_report(numeric_cols, group_cols, stress_dict)\n",
    "\n",
    "    print(\"\\nDone:\")\n",
    "    print(\"- 01_figures\")\n",
    "    print(\"- 02_numeric_columns_used.csv / 02_group_columns_used.csv\")\n",
    "    print(\"- 03_zscores.csv\")\n",
    "    print(\"- 04_D_euclidean.csv / 04_D_braycurtis.csv\")\n",
    "    print(\"- 05_mds_coordinates.csv\")\n",
    "    print(\"- 06_metric_mds_euclidean.png / 07_nonmetric_mds_euclidean.png / 08_metric_mds_braycurtis.png\")\n",
    "    if map_path:\n",
    "        print(\"- 00_map_lonlat.png (simple lon/lat map)\")\n",
    "    print(\"- 90_combined_original_z_mds.csv\")\n",
    "    print(\"- 99_REPORT.md\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed48e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done:\n",
      "- 01_figures\n",
      "- 02_numeric_columns_used.csv / 02_group_columns_used.csv\n",
      "- 03_zscores.csv\n",
      "- 04_D_euclidean.csv / 04_D_braycurtis.csv\n",
      "- 05_mds_coordinates.csv\n",
      "- 06_metric_mds_euclidean.png / 07_nonmetric_mds_euclidean.png / 08_metric_mds_braycurtis.png\n",
      "- 00_map_lonlat.png (simple lon/lat map)\n",
      "- 90_combined_original_z_mds.csv\n",
      "- 99_REPORT.md\n"
     ]
    }
   ],
   "source": [
    "# Execute this line to run the final project\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e92460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
